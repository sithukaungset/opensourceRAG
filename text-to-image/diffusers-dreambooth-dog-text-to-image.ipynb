{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text-to-image dreambooth finetuning using transformers specific pipeline component\n",
    "\n",
    "DreamBooth is a method for personalizing text-to-image models. It fine-tunes these models using 5-10 images of a specific subject, allowing them to generate personalized images based on textual prompts.\n",
    "\n",
    "This sample shows how to use `diffusers_text_to_image_dreambooth_pipeline` component from the `azureml` system registry to fine tune a model for text to image task using dog Dataset. We then deploy the fine tuned model to an online endpoint for real time inference.\n",
    "\n",
    "### Training data\n",
    "We will use the [dog-example](https://huggingface.co/datasets/diffusers/dog-example) dataset.\n",
    "\n",
    "### Model\n",
    "We will use the `runwayml-stable-diffusion-v1-5` model in this notebook. If you need to fine tune a model that is available on HuggingFace, but not available in `azureml` system registry, you can either register the model and use the registered model or use the `model_name` parameter to instruct the components to pull the model directly from HuggingFace.\n",
    "\n",
    "### Outline\n",
    "1. Install dependencies\n",
    "2. Setup pre-requisites such as compute\n",
    "3. Pick a model to fine tune\n",
    "4. Prepare dataset for finetuning the model\n",
    "5. Submit the fine tuning job using diffusers specific text-to-image dreambooth fine tuning component\n",
    "6. Review training metrics\n",
    "7. Register the fine tuned model\n",
    "8. Deploy the fine tuned model for real time inference\n",
    "9. Test deployed end point\n",
    "9. Clean up resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Install dependencies\n",
    "Before starting off, if you are running the notebook on Azure Machine Learning Studio or running first time locally, you will need the following packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure-ai-ml==1.8.0\n",
      "  Downloading azure_ai_ml-1.8.0-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.1.0 in c:\\programdata\\anaconda3\\envs\\llama-cpp-env\\lib\\site-packages (from azure-ai-ml==1.8.0) (6.0.2)\n",
      "Collecting msrest>=0.6.18 (from azure-ai-ml==1.8.0)\n",
      "  Downloading msrest-0.7.1-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting azure-core<2.0.0,>=1.23.0 (from azure-ai-ml==1.8.0)\n",
      "  Downloading azure_core-1.30.2-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting azure-mgmt-core<2.0.0,>=1.3.0 (from azure-ai-ml==1.8.0)\n",
      "  Downloading azure_mgmt_core-1.4.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.5 in c:\\programdata\\anaconda3\\envs\\llama-cpp-env\\lib\\site-packages (from azure-ai-ml==1.8.0) (3.21.3)\n",
      "Collecting jsonschema<5.0.0,>=4.0.0 (from azure-ai-ml==1.8.0)\n",
      "  Downloading jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0 in c:\\programdata\\anaconda3\\envs\\llama-cpp-env\\lib\\site-packages (from azure-ai-ml==1.8.0) (4.66.5)\n",
      "Collecting strictyaml<2.0.0 (from azure-ai-ml==1.8.0)\n",
      "  Downloading strictyaml-1.7.3-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: colorama<0.5.0 in c:\\programdata\\anaconda3\\envs\\llama-cpp-env\\lib\\site-packages (from azure-ai-ml==1.8.0) (0.4.6)\n",
      "Collecting pyjwt<3.0.0 (from azure-ai-ml==1.8.0)\n",
      "  Downloading PyJWT-2.9.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting azure-storage-blob<13.0.0,>=12.10.0 (from azure-ai-ml==1.8.0)\n",
      "  Downloading azure_storage_blob-12.22.0-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting azure-storage-file-share<13.0.0 (from azure-ai-ml==1.8.0)\n",
      "  Downloading azure_storage_file_share-12.17.0-py3-none-any.whl.metadata (47 kB)\n",
      "Collecting azure-storage-file-datalake<13.0.0 (from azure-ai-ml==1.8.0)\n",
      "  Downloading azure_storage_file_datalake-12.16.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydash<6.0.0 (from azure-ai-ml==1.8.0)\n",
      "  Downloading pydash-5.1.2-py3-none-any.whl.metadata (42 kB)\n",
      "Collecting isodate (from azure-ai-ml==1.8.0)\n",
      "  Using cached isodate-0.6.1-py2.py3-none-any.whl.metadata (9.6 kB)\n",
      "Collecting azure-common<2.0.0,>=1.1 (from azure-ai-ml==1.8.0)\n",
      "  Downloading azure_common-1.1.28-py2.py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: typing-extensions<5.0.0 in c:\\programdata\\anaconda3\\envs\\llama-cpp-env\\lib\\site-packages (from azure-ai-ml==1.8.0) (4.12.2)\n",
      "Collecting opencensus-ext-azure<2.0.0 (from azure-ai-ml==1.8.0)\n",
      "  Downloading opencensus_ext_azure-1.1.13-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: requests>=2.21.0 in c:\\programdata\\anaconda3\\envs\\llama-cpp-env\\lib\\site-packages (from azure-core<2.0.0,>=1.23.0->azure-ai-ml==1.8.0) (2.32.3)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\programdata\\anaconda3\\envs\\llama-cpp-env\\lib\\site-packages (from azure-core<2.0.0,>=1.23.0->azure-ai-ml==1.8.0) (1.16.0)\n",
      "Collecting cryptography>=2.1.4 (from azure-storage-blob<13.0.0,>=12.10.0->azure-ai-ml==1.8.0)\n",
      "  Downloading cryptography-43.0.0-cp39-abi3-win_amd64.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\programdata\\anaconda3\\envs\\llama-cpp-env\\lib\\site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml==1.8.0) (24.2.0)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml==1.8.0)\n",
      "  Downloading jsonschema_specifications-2023.12.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml==1.8.0)\n",
      "  Downloading referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml==1.8.0)\n",
      "  Downloading rpds_py-0.20.0-cp312-none-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\programdata\\anaconda3\\envs\\llama-cpp-env\\lib\\site-packages (from marshmallow<4.0.0,>=3.5->azure-ai-ml==1.8.0) (24.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\envs\\llama-cpp-env\\lib\\site-packages (from msrest>=0.6.18->azure-ai-ml==1.8.0) (2024.7.4)\n",
      "Collecting requests-oauthlib>=0.5.0 (from msrest>=0.6.18->azure-ai-ml==1.8.0)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting azure-identity<2.0.0,>=1.5.0 (from opencensus-ext-azure<2.0.0->azure-ai-ml==1.8.0)\n",
      "  Downloading azure_identity-1.17.1-py3-none-any.whl.metadata (79 kB)\n",
      "Collecting opencensus<1.0.0,>=0.11.4 (from opencensus-ext-azure<2.0.0->azure-ai-ml==1.8.0)\n",
      "  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: psutil>=5.6.3 in c:\\programdata\\anaconda3\\envs\\llama-cpp-env\\lib\\site-packages (from opencensus-ext-azure<2.0.0->azure-ai-ml==1.8.0) (6.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.0 in c:\\programdata\\anaconda3\\envs\\llama-cpp-env\\lib\\site-packages (from strictyaml<2.0.0->azure-ai-ml==1.8.0) (2.9.0)\n",
      "Collecting msal>=1.24.0 (from azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure<2.0.0->azure-ai-ml==1.8.0)\n",
      "  Downloading msal-1.30.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting msal-extensions>=0.3.0 (from azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure<2.0.0->azure-ai-ml==1.8.0)\n",
      "  Downloading msal_extensions-1.2.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting cffi>=1.12 (from cryptography>=2.1.4->azure-storage-blob<13.0.0,>=12.10.0->azure-ai-ml==1.8.0)\n",
      "  Downloading cffi-1.17.0-cp312-cp312-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting opencensus-context>=0.1.3 (from opencensus<1.0.0,>=0.11.4->opencensus-ext-azure<2.0.0->azure-ai-ml==1.8.0)\n",
      "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting google-api-core<3.0.0,>=1.0.0 (from opencensus<1.0.0,>=0.11.4->opencensus-ext-azure<2.0.0->azure-ai-ml==1.8.0)\n",
      "  Downloading google_api_core-2.19.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\envs\\llama-cpp-env\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.23.0->azure-ai-ml==1.8.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\envs\\llama-cpp-env\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.23.0->azure-ai-ml==1.8.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\envs\\llama-cpp-env\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.23.0->azure-ai-ml==1.8.0) (2.2.2)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.5.0->msrest>=0.6.18->azure-ai-ml==1.8.0)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting pycparser (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob<13.0.0,>=12.10.0->azure-ai-ml==1.8.0)\n",
      "  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure<2.0.0->azure-ai-ml==1.8.0)\n",
      "  Downloading googleapis_common_protos-1.65.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure<2.0.0->azure-ai-ml==1.8.0)\n",
      "  Downloading protobuf-5.28.0-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure<2.0.0->azure-ai-ml==1.8.0)\n",
      "  Downloading proto_plus-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-auth<3.0.dev0,>=2.14.1 (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure<2.0.0->azure-ai-ml==1.8.0)\n",
      "  Downloading google_auth-2.34.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting portalocker<3,>=1.4 (from msal-extensions>=0.3.0->azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure<2.0.0->azure-ai-ml==1.8.0)\n",
      "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure<2.0.0->azure-ai-ml==1.8.0)\n",
      "  Downloading cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure<2.0.0->azure-ai-ml==1.8.0)\n",
      "  Downloading pyasn1_modules-0.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure<2.0.0->azure-ai-ml==1.8.0)\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\programdata\\anaconda3\\envs\\llama-cpp-env\\lib\\site-packages (from portalocker<3,>=1.4->msal-extensions>=0.3.0->azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure<2.0.0->azure-ai-ml==1.8.0) (306)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure<2.0.0->azure-ai-ml==1.8.0)\n",
      "  Downloading pyasn1-0.6.0-py2.py3-none-any.whl.metadata (8.3 kB)\n",
      "Downloading azure_ai_ml-1.8.0-py3-none-any.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 1.0/6.2 MB 8.5 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 2.1/6.2 MB 5.3 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 3.1/6.2 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 3.4/6.2 MB 3.9 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 4.2/6.2 MB 4.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 5.2/6.2 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 4.1 MB/s eta 0:00:00\n",
      "Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
      "Downloading azure_core-1.30.2-py3-none-any.whl (194 kB)\n",
      "Downloading azure_mgmt_core-1.4.0-py3-none-any.whl (27 kB)\n",
      "Downloading azure_storage_blob-12.22.0-py3-none-any.whl (404 kB)\n",
      "Downloading azure_storage_file_datalake-12.16.0-py3-none-any.whl (255 kB)\n",
      "Downloading azure_storage_file_share-12.17.0-py3-none-any.whl (270 kB)\n",
      "Using cached isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "Downloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Downloading msrest-0.7.1-py3-none-any.whl (85 kB)\n",
      "Downloading opencensus_ext_azure-1.1.13-py2.py3-none-any.whl (43 kB)\n",
      "Downloading pydash-5.1.2-py3-none-any.whl (84 kB)\n",
      "Downloading PyJWT-2.9.0-py3-none-any.whl (22 kB)\n",
      "Downloading strictyaml-1.7.3-py3-none-any.whl (123 kB)\n",
      "Downloading azure_identity-1.17.1-py3-none-any.whl (173 kB)\n",
      "Downloading cryptography-43.0.0-cp39-abi3-win_amd64.whl (3.1 MB)\n",
      "   ---------------------------------------- 0.0/3.1 MB ? eta -:--:--\n",
      "   --------------------------- ------------ 2.1/3.1 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.1/3.1 MB 9.0 MB/s eta 0:00:00\n",
      "Downloading jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB)\n",
      "Downloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
      "Downloading referencing-0.35.1-py3-none-any.whl (26 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading rpds_py-0.20.0-cp312-none-win_amd64.whl (214 kB)\n",
      "Downloading cffi-1.17.0-cp312-cp312-win_amd64.whl (181 kB)\n",
      "Downloading google_api_core-2.19.2-py3-none-any.whl (139 kB)\n",
      "Downloading msal-1.30.0-py3-none-any.whl (111 kB)\n",
      "Downloading msal_extensions-1.2.0-py3-none-any.whl (19 kB)\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
      "Downloading google_auth-2.34.0-py2.py3-none-any.whl (200 kB)\n",
      "Downloading googleapis_common_protos-1.65.0-py2.py3-none-any.whl (220 kB)\n",
      "Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
      "Downloading proto_plus-1.24.0-py3-none-any.whl (50 kB)\n",
      "Downloading protobuf-5.28.0-cp310-abi3-win_amd64.whl (431 kB)\n",
      "Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Downloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Downloading pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
      "Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n",
      "Installing collected packages: opencensus-context, azure-common, rpds-py, pyjwt, pydash, pycparser, pyasn1, protobuf, portalocker, oauthlib, isodate, cachetools, strictyaml, rsa, requests-oauthlib, referencing, pyasn1-modules, proto-plus, googleapis-common-protos, cffi, azure-core, msrest, jsonschema-specifications, google-auth, cryptography, azure-mgmt-core, jsonschema, google-api-core, azure-storage-file-share, azure-storage-blob, opencensus, msal, azure-storage-file-datalake, msal-extensions, azure-identity, opencensus-ext-azure, azure-ai-ml\n",
      "Successfully installed azure-ai-ml-1.8.0 azure-common-1.1.28 azure-core-1.30.2 azure-identity-1.17.1 azure-mgmt-core-1.4.0 azure-storage-blob-12.22.0 azure-storage-file-datalake-12.16.0 azure-storage-file-share-12.17.0 cachetools-5.5.0 cffi-1.17.0 cryptography-43.0.0 google-api-core-2.19.2 google-auth-2.34.0 googleapis-common-protos-1.65.0 isodate-0.6.1 jsonschema-4.23.0 jsonschema-specifications-2023.12.1 msal-1.30.0 msal-extensions-1.2.0 msrest-0.7.1 oauthlib-3.2.2 opencensus-0.11.4 opencensus-context-0.1.3 opencensus-ext-azure-1.1.13 portalocker-2.10.1 proto-plus-1.24.0 protobuf-5.28.0 pyasn1-0.6.0 pyasn1-modules-0.4.0 pycparser-2.22 pydash-5.1.2 pyjwt-2.9.0 referencing-0.35.1 requests-oauthlib-2.0.0 rpds-py-0.20.0 rsa-4.9 strictyaml-1.7.3\n",
      "Collecting azure-identity==1.13.0\n",
      "  Downloading azure_identity-1.13.0-py3-none-any.whl.metadata (67 kB)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.11.0 in c:\\programdata\\anaconda3\\envs\\llama-cpp-env\\lib\\site-packages (from azure-identity==1.13.0) (1.30.2)\n",
      "Requirement already satisfied: cryptography>=2.5 in c:\\programdata\\anaconda3\\envs\\llama-cpp-env\\lib\\site-packages (from azure-identity==1.13.0) (43.0.0)\n",
      "Requirement already satisfied: msal<2.0.0,>=1.20.0 in c:\\programdata\\anaconda3\\envs\\llama-cpp-env\\lib\\site-packages (from azure-identity==1.13.0) (1.30.0)\n",
      "Requirement already satisfied: msal-extensions<2.0.0,>=0.3.0 in c:\\programdata\\anaconda3\\envs\\llama-cpp-env\\lib\\site-packages (from azure-identity==1.13.0) (1.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\envs\\llama-cpp-env\\lib\\site-packages (from azure-identity==1.13.0) (1.16.0)\n",
      "Requirement already satisfied: requests>=2.21.0 in c:\\programdata\\anaconda3\\envs\\llama-cpp-env\\lib\\site-packages (from azure-core<2.0.0,>=1.11.0->azure-identity==1.13.0) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\programdata\\anaconda3\\envs\\llama-cpp-env\\lib\\site-packages (from azure-core<2.0.0,>=1.11.0->azure-identity==1.13.0) (4.12.2)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\programdata\\anaconda3\\envs\\llama-cpp-env\\lib\\site-packages (from cryptography>=2.5->azure-identity==1.13.0) (1.17.0)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in c:\\programdata\\anaconda3\\envs\\llama-cpp-env\\lib\\site-packages (from PyJWT[crypto]<3,>=1.0.0->msal<2.0.0,>=1.20.0->azure-identity==1.13.0) (2.9.0)\n",
      "Requirement already satisfied: portalocker<3,>=1.4 in c:\\programdata\\anaconda3\\envs\\llama-cpp-env\\lib\\site-packages (from msal-extensions<2.0.0,>=0.3.0->azure-identity==1.13.0) (2.10.1)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\envs\\llama-cpp-env\\lib\\site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity==1.13.0) (2.22)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\programdata\\anaconda3\\envs\\llama-cpp-env\\lib\\site-packages (from portalocker<3,>=1.4->msal-extensions<2.0.0,>=0.3.0->azure-identity==1.13.0) (306)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\envs\\llama-cpp-env\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.11.0->azure-identity==1.13.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\envs\\llama-cpp-env\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.11.0->azure-identity==1.13.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\envs\\llama-cpp-env\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.11.0->azure-identity==1.13.0) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\envs\\llama-cpp-env\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.11.0->azure-identity==1.13.0) (2024.7.4)\n",
      "Downloading azure_identity-1.13.0-py3-none-any.whl (151 kB)\n",
      "Installing collected packages: azure-identity\n",
      "  Attempting uninstall: azure-identity\n",
      "    Found existing installation: azure-identity 1.17.1\n",
      "    Uninstalling azure-identity-1.17.1:\n",
      "      Successfully uninstalled azure-identity-1.17.1\n",
      "Successfully installed azure-identity-1.13.0\n"
     ]
    }
   ],
   "source": [
    "! pip install azure-ai-ml==1.8.0\n",
    "! pip install azure-identity==1.13.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Setup pre-requisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Connect to Azure Machine Learning workspace\n",
    "\n",
    "Before we dive in the code, you'll need to connect to your workspace. The workspace is the top-level resource for Azure Machine Learning, providing a centralized place to work with all the artifacts you create when you use Azure Machine Learning.\n",
    "\n",
    "We are using `DefaultAzureCredential` to get access to workspace. `DefaultAzureCredential` should be capable of handling most scenarios. If you want to learn more about other available credentials, go to [set up authentication doc](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-setup-authentication?tabs=sdk), [azure-identity reference doc](https://learn.microsoft.com/en-us/python/api/azure-identity/azure.identity?view=azure-python).\n",
    "\n",
    "Replace `AML_WORKSPACE_NAME`, `RESOURCE_GROUP` and `SUBSCRIPTION_ID` with their respective values in the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We could not find config.json in: . or in its parent directories. Please provide the full path to the config file or ensure that config.json exists in the parent directories.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DefaultAzureCredential failed to retrieve a token from the included credentials.\n",
      "Attempted credentials:\n",
      "\tEnvironmentCredential: EnvironmentCredential authentication unavailable. Environment variables are not fully configured.\n",
      "Visit https://aka.ms/azsdk/python/identity/environmentcredential/troubleshoot to troubleshoot this issue.\n",
      "\tManagedIdentityCredential: ManagedIdentityCredential authentication unavailable, no response from the IMDS endpoint.\n",
      "\tSharedTokenCacheCredential: SharedTokenCacheCredential authentication unavailable. No accounts were found in the cache.\n",
      "\tAzureCliCredential: Azure CLI not found on path\n",
      "\tAzurePowerShellCredential: Az.Account module >= 2.2.0 is not installed\n",
      "\tAzureDeveloperCliCredential: Azure Developer CLI could not be found. Please visit https://aka.ms/azure-dev for installation instructions and then,once installed, authenticate to your Azure account using 'azd auth login'.\n",
      "To mitigate this issue, please refer to the troubleshooting guidelines here at https://aka.ms/azsdk/python/identity/defaultazurecredential/troubleshoot.\n"
     ]
    },
    {
     "ename": "ClientAuthenticationError",
     "evalue": "DefaultAzureCredential failed to retrieve a token from the included credentials.\nAttempted credentials:\n\tEnvironmentCredential: EnvironmentCredential authentication unavailable. Environment variables are not fully configured.\nVisit https://aka.ms/azsdk/python/identity/environmentcredential/troubleshoot to troubleshoot this issue.\n\tManagedIdentityCredential: ManagedIdentityCredential authentication unavailable, no response from the IMDS endpoint.\n\tSharedTokenCacheCredential: SharedTokenCacheCredential authentication unavailable. No accounts were found in the cache.\n\tAzureCliCredential: Azure CLI not found on path\n\tAzurePowerShellCredential: Az.Account module >= 2.2.0 is not installed\n\tAzureDeveloperCliCredential: Azure Developer CLI could not be found. Please visit https://aka.ms/azure-dev for installation instructions and then,once installed, authenticate to your Azure account using 'azd auth login'.\nTo mitigate this issue, please refer to the troubleshooting guidelines here at https://aka.ms/azsdk/python/identity/defaultazurecredential/troubleshoot.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mClientAuthenticationError\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 24\u001b[0m\n\u001b[0;32m     19\u001b[0m     workspace_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAML_WORKSPACE_NAME\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     21\u001b[0m workspace_ml_client \u001b[38;5;241m=\u001b[39m MLClient(\n\u001b[0;32m     22\u001b[0m     credential, subscription_id, resource_group, workspace_name\n\u001b[0;32m     23\u001b[0m )\n\u001b[1;32m---> 24\u001b[0m registry_ml_client \u001b[38;5;241m=\u001b[39m \u001b[43mMLClient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcredential\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubscription_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresource_group\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mregistry_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mazureml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\llama-cpp-env\\Lib\\site-packages\\azure\\ai\\ml\\_ml_client.py:226\u001b[0m, in \u001b[0;36mMLClient.__init__\u001b[1;34m(self, credential, subscription_id, resource_group_name, workspace_name, registry_name, **kwargs)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;66;03m# registry_name is present when the operations need referring assets from registry.\u001b[39;00m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;66;03m# the subscription, resource group, if provided, will be ignored and replaced by\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;66;03m# whatever is received from the registry discovery service.\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m registry_name:\n\u001b[1;32m--> 226\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_service_client_10_2021_dataplanepreview, resource_group_name, subscription_id \u001b[38;5;241m=\u001b[39m \u001b[43mget_registry_client\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_credential\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregistry_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_operation_scope \u001b[38;5;241m=\u001b[39m OperationScope(subscription_id, resource_group_name, workspace_name, registry_name)\n\u001b[0;32m    232\u001b[0m \u001b[38;5;66;03m# Cannot send multiple base_url as azure-cli sets the base_url automatically.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\llama-cpp-env\\Lib\\site-packages\\azure\\ai\\ml\\_utils\\_registry_utils.py:188\u001b[0m, in \u001b[0;36mget_registry_client\u001b[1;34m(credential, registry_name, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m service_client_registry_discovery_client \u001b[38;5;241m=\u001b[39m ServiceClientRegistryDiscovery(\n\u001b[0;32m    183\u001b[0m     credential\u001b[38;5;241m=\u001b[39mcredential, base_url\u001b[38;5;241m=\u001b[39mbase_url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    184\u001b[0m )\n\u001b[0;32m    185\u001b[0m registry_discovery \u001b[38;5;241m=\u001b[39m RegistryDiscovery(\n\u001b[0;32m    186\u001b[0m     credential, registry_name, service_client_registry_discovery_client, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    187\u001b[0m )\n\u001b[1;32m--> 188\u001b[0m service_client_10_2021_dataplanepreview \u001b[38;5;241m=\u001b[39m \u001b[43mregistry_discovery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_registry_service_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m subscription_id \u001b[38;5;241m=\u001b[39m registry_discovery\u001b[38;5;241m.\u001b[39msubscription_id\n\u001b[0;32m    190\u001b[0m resource_group_name \u001b[38;5;241m=\u001b[39m registry_discovery\u001b[38;5;241m.\u001b[39mresource_group\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\llama-cpp-env\\Lib\\site-packages\\azure\\ai\\ml\\_utils\\_registry_utils.py:50\u001b[0m, in \u001b[0;36mRegistryDiscovery.get_registry_service_client\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_registry_service_client\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AzureMachineLearningWorkspaces:\n\u001b[1;32m---> 50\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_registry_details\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubscription_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresource_group\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\llama-cpp-env\\Lib\\site-packages\\azure\\ai\\ml\\_utils\\_registry_utils.py:42\u001b[0m, in \u001b[0;36mRegistryDiscovery._get_registry_details\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_registry_details\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m---> 42\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mservice_client_registry_discovery_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregistry_management_non_workspace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregistry_management_non_workspace\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=line-too-long\u001b[39;49;00m\n\u001b[0;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregistry_name\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_base_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mprimary_region_resource_provider_uri\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mMFE_PATH_PREFIX\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_subscription_id \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39msubscription_id\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\llama-cpp-env\\Lib\\site-packages\\azure\\core\\tracing\\decorator.py:94\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     92\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\llama-cpp-env\\Lib\\site-packages\\azure\\ai\\ml\\_restclient\\registry_discovery\\operations\\_registry_management_non_workspace_operations.py:111\u001b[0m, in \u001b[0;36mRegistryManagementNonWorkspaceOperations.registry_management_non_workspace\u001b[1;34m(self, registry_name, **kwargs)\u001b[0m\n\u001b[0;32m    108\u001b[0m request \u001b[38;5;241m=\u001b[39m _convert_request(request)\n\u001b[0;32m    109\u001b[0m request\u001b[38;5;241m.\u001b[39murl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mformat_url(request\u001b[38;5;241m.\u001b[39murl)\n\u001b[1;32m--> 111\u001b[0m pipeline_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m response \u001b[38;5;241m=\u001b[39m pipeline_response\u001b[38;5;241m.\u001b[39mhttp_response\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m200\u001b[39m]:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\llama-cpp-env\\Lib\\site-packages\\azure\\core\\pipeline\\_base.py:229\u001b[0m, in \u001b[0;36mPipeline.run\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    227\u001b[0m pipeline_request: PipelineRequest[HTTPRequestType] \u001b[38;5;241m=\u001b[39m PipelineRequest(request, context)\n\u001b[0;32m    228\u001b[0m first_node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl_policies[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl_policies \u001b[38;5;28;01melse\u001b[39;00m _TransportRunner(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport)\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfirst_node\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline_request\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\llama-cpp-env\\Lib\\site-packages\\azure\\core\\pipeline\\_base.py:86\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     84\u001b[0m _await_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_policy\u001b[38;5;241m.\u001b[39mon_request, request)\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 86\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     88\u001b[0m     _await_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_policy\u001b[38;5;241m.\u001b[39mon_exception, request)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\llama-cpp-env\\Lib\\site-packages\\azure\\core\\pipeline\\_base.py:86\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     84\u001b[0m _await_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_policy\u001b[38;5;241m.\u001b[39mon_request, request)\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 86\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     88\u001b[0m     _await_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_policy\u001b[38;5;241m.\u001b[39mon_exception, request)\n",
      "    \u001b[1;31m[... skipping similar frames: _SansIOHTTPPolicyRunner.send at line 86 (2 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\llama-cpp-env\\Lib\\site-packages\\azure\\core\\pipeline\\_base.py:86\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     84\u001b[0m _await_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_policy\u001b[38;5;241m.\u001b[39mon_request, request)\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 86\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     88\u001b[0m     _await_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_policy\u001b[38;5;241m.\u001b[39mon_exception, request)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\llama-cpp-env\\Lib\\site-packages\\azure\\mgmt\\core\\policies\\_base.py:46\u001b[0m, in \u001b[0;36mARMAutoResourceProviderRegistrationPolicy.send\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend\u001b[39m(\u001b[38;5;28mself\u001b[39m, request):\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;66;03m# type: (PipelineRequest[HTTPRequestType], Any) -> PipelineResponse[HTTPRequestType, HTTPResponseType]\u001b[39;00m\n\u001b[0;32m     45\u001b[0m     http_request \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mhttp_request\n\u001b[1;32m---> 46\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mhttp_response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m409\u001b[39m:\n\u001b[0;32m     48\u001b[0m         rp_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_rp_not_registered_err(response)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\llama-cpp-env\\Lib\\site-packages\\azure\\core\\pipeline\\policies\\_redirect.py:197\u001b[0m, in \u001b[0;36mRedirectPolicy.send\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    195\u001b[0m original_domain \u001b[38;5;241m=\u001b[39m get_domain(request\u001b[38;5;241m.\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39murl) \u001b[38;5;28;01mif\u001b[39;00m redirect_settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m retryable:\n\u001b[1;32m--> 197\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m     redirect_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_redirect_location(response)\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m redirect_location \u001b[38;5;129;01mand\u001b[39;00m redirect_settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\llama-cpp-env\\Lib\\site-packages\\azure\\core\\pipeline\\policies\\_retry.py:532\u001b[0m, in \u001b[0;36mRetryPolicy.send\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_timeout(request, absolute_timeout, is_response_error)\n\u001b[0;32m    531\u001b[0m request\u001b[38;5;241m.\u001b[39mcontext[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mretry_count\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(retry_settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistory\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m--> 532\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_retry(retry_settings, response):\n\u001b[0;32m    534\u001b[0m     retry_active \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mincrement(retry_settings, response\u001b[38;5;241m=\u001b[39mresponse)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\llama-cpp-env\\Lib\\site-packages\\azure\\core\\pipeline\\policies\\_authentication.py:124\u001b[0m, in \u001b[0;36mBearerTokenCredentialPolicy.send\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: PipelineRequest[HTTPRequestType]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PipelineResponse[HTTPRequestType, HTTPResponseType]:\n\u001b[0;32m    117\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Authorize request with a bearer token and send it to the next policy\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \n\u001b[0;32m    119\u001b[0m \u001b[38;5;124;03m    :param request: The pipeline request object\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;124;03m    :rtype: ~azure.core.pipeline.PipelineResponse\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    126\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext\u001b[38;5;241m.\u001b[39msend(request)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\llama-cpp-env\\Lib\\site-packages\\azure\\core\\pipeline\\policies\\_authentication.py:99\u001b[0m, in \u001b[0;36mBearerTokenCredentialPolicy.on_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_credential\u001b[38;5;241m.\u001b[39mget_token(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_scopes, enable_cae\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_cae)\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 99\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_credential\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_token\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_scopes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_headers(request\u001b[38;5;241m.\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39mheaders, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_token\u001b[38;5;241m.\u001b[39mtoken)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\llama-cpp-env\\Lib\\site-packages\\azure\\identity\\_credentials\\default.py:214\u001b[0m, in \u001b[0;36mDefaultAzureCredential.get_token\u001b[1;34m(self, *scopes, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     _LOGGER\u001b[38;5;241m.\u001b[39minfo(\n\u001b[0;32m    210\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m acquired a token from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_successful_credential\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m    211\u001b[0m     )\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m token\n\u001b[1;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mDefaultAzureCredential\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_token\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mscopes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\llama-cpp-env\\Lib\\site-packages\\azure\\identity\\_credentials\\chained.py:111\u001b[0m, in \u001b[0;36mChainedTokenCredential.get_token\u001b[1;34m(self, *scopes, **kwargs)\u001b[0m\n\u001b[0;32m    107\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m failed to retrieve a token from the included credentials.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m attempts \\\n\u001b[0;32m    108\u001b[0m           \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTo mitigate this issue, please refer to the troubleshooting guidelines here at \u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[0;32m    109\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://aka.ms/azsdk/python/identity/defaultazurecredential/troubleshoot.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    110\u001b[0m _LOGGER\u001b[38;5;241m.\u001b[39mwarning(message)\n\u001b[1;32m--> 111\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ClientAuthenticationError(message\u001b[38;5;241m=\u001b[39mmessage)\n",
      "\u001b[1;31mClientAuthenticationError\u001b[0m: DefaultAzureCredential failed to retrieve a token from the included credentials.\nAttempted credentials:\n\tEnvironmentCredential: EnvironmentCredential authentication unavailable. Environment variables are not fully configured.\nVisit https://aka.ms/azsdk/python/identity/environmentcredential/troubleshoot to troubleshoot this issue.\n\tManagedIdentityCredential: ManagedIdentityCredential authentication unavailable, no response from the IMDS endpoint.\n\tSharedTokenCacheCredential: SharedTokenCacheCredential authentication unavailable. No accounts were found in the cache.\n\tAzureCliCredential: Azure CLI not found on path\n\tAzurePowerShellCredential: Az.Account module >= 2.2.0 is not installed\n\tAzureDeveloperCliCredential: Azure Developer CLI could not be found. Please visit https://aka.ms/azure-dev for installation instructions and then,once installed, authenticate to your Azure account using 'azd auth login'.\nTo mitigate this issue, please refer to the troubleshooting guidelines here at https://aka.ms/azsdk/python/identity/defaultazurecredential/troubleshoot."
     ]
    }
   ],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "\n",
    "experiment_name = \"AzureML-Train-Finetune-MultiModal-TextToImage-DreamBooth-Samples\"  # can rename to any valid name\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "workspace_ml_client = None\n",
    "try:\n",
    "    workspace_ml_client = MLClient.from_config(credential)\n",
    "    subscription_id = workspace_ml_client.subscription_id\n",
    "    resource_group = workspace_ml_client.resource_group_name\n",
    "    workspace_name = workspace_ml_client.workspace_name\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "    # Enter details of your AML workspace\n",
    "    subscription_id = \"c53bdcf6-8fac-491b-8692-9195df094803\"\n",
    "    resource_group = \"ChatGPTAOAIteam\"\n",
    "    workspace_name = \"slm-innovator\"\n",
    "\n",
    "workspace_ml_client = MLClient(\n",
    "    credential, subscription_id, resource_group, workspace_name\n",
    ")\n",
    "registry_ml_client = MLClient(\n",
    "    credential,\n",
    "    subscription_id,\n",
    "    resource_group,\n",
    "    registry_name=\"azureml\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Create compute\n",
    "\n",
    "In order to finetune a model on Azure Machine Learning studio, you will need to create a compute resource first. **Creating a compute will take 3-4 minutes.** \n",
    "\n",
    "For additional references, see [Azure Machine Learning in a Day](https://github.com/Azure/azureml-examples/blob/main/tutorials/azureml-in-a-day/azureml-in-a-day.ipynb). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import AmlCompute\n",
    "from azure.core.exceptions import ResourceNotFoundError\n",
    "\n",
    "cluster_name = \"sample-finetune-cluster-gpu\"\n",
    "\n",
    "try:\n",
    "    _ = workspace_ml_client.compute.get(cluster_name)\n",
    "    print(\"Found existing compute target.\")\n",
    "except ResourceNotFoundError:\n",
    "    print(\"Creating a new compute target...\")\n",
    "    compute_config = AmlCompute(\n",
    "        name=cluster_name,\n",
    "        type=\"amlcompute\",\n",
    "        size=\"Standard_NC6s_v3\",\n",
    "        idle_time_before_scale_down=120,\n",
    "        min_instances=0,\n",
    "        max_instances=4,\n",
    "    )\n",
    "    workspace_ml_client.begin_create_or_update(compute_config).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Pick a foundation model to fine tune\n",
    "\n",
    "We will use the `runwayml-stable-diffusion-v1-5` model in this notebook. If you need to fine tune a model that is available on HuggingFace, but not available in `azureml` system registry, you can either register the model and use the registered model or provide huggingface model_id in the `model_name` parameter to instruct the components to pull the model directly from HuggingFace.\n",
    "\n",
    "Currently following models are supported:\n",
    "\n",
    "| Model Name | Source |\n",
    "| ------ | ---------- |\n",
    "| [runwayml-stable-diffusion-v1-5](https://ml.azure.com/registries/azureml/models/runwayml-stable-diffusion-v1-5/version/8) | azureml registry |\n",
    "| [stabilityai-stable-diffusion-2-1](https://ml.azure.com/registries/azureml/models/stabilityai-stable-diffusion-2-1/version/8) | azureml registry |\n",
    "| [compvis-stable-diffusion-v1-4](https://ml.azure.com/registries/azureml/models/compvis-stable-diffusion-v1-4/version/8) | azureml registry |\n",
    "| [Text to Image models from Huggingface's Transformer library](https://huggingface.co/models?pipeline_tag=text-to-image&library=transformers)| HuggingFace |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_model_name = \"runwayml/stable-diffusion-v1-5\"\n",
    "\n",
    "aml_registry_model_name = \"runwayml-stable-diffusion-v1-5\"\n",
    "foundation_models = registry_ml_client.models.list(aml_registry_model_name)\n",
    "foundation_model = max(foundation_models, key=lambda x: int(x.version))\n",
    "print(\n",
    "    f\"\\n\\nUsing model name: {foundation_model.name}, version: {foundation_model.version}, id: {foundation_model.id} for fine tuning\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Prepare the dataset for fine-tuning the model\n",
    "\n",
    "We will use the [dog-example](https://huggingface.co/datasets/diffusers/dog-example) dataset. It consists of 5 dog images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Download the Data\n",
    "\n",
    "For dreambooth training, we need few images in the folder. We will download the dog-example dataset locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import os\n",
    "\n",
    "url = \"https://datasets-server.huggingface.co/rows?dataset=diffusers%2Fdog-example&config=default&split=train&offset=0&length=100\"\n",
    "dataset_dir = \"dog-example\"\n",
    "\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()\n",
    "\n",
    "# Parse the JSON content\n",
    "data = json.loads(response.content)\n",
    "data = data[\"rows\"]\n",
    "# Create a directory for the images\n",
    "os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "# Iterate over the parsed data and download each image\n",
    "for i, item in enumerate(data):\n",
    "    image_url = item[\"row\"][\"image\"][\"src\"]\n",
    "    image_response = requests.get(image_url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    image_response.raise_for_status()\n",
    "\n",
    "    # Write the image data to a file\n",
    "    with open(os.path.join(dataset_dir, f\"image_{i}.jpeg\"), \"wb\") as f:\n",
    "        f.write(image_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import Image\n",
    "\n",
    "files = os.listdir(dataset_dir)\n",
    "image_file = [file for file in files if file.endswith((\".jpg\", \".jpeg\", \".png\"))][0]\n",
    "sample_image = os.path.join(dataset_dir, image_file)\n",
    "Image(filename=sample_image, width=400, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Upload the images to Datastore through an AML Data asset (URI Folder)\n",
    "\n",
    "In order to use the data for training in Azure ML, we upload it to our default Azure Blob Storage of our  Azure ML Workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uploading image files by creating a 'data asset URI FOLDER':\n",
    "\n",
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "instance_data = Data(\n",
    "    path=dataset_dir,\n",
    "    type=AssetTypes.URI_FOLDER,\n",
    "    description=\"Dog images for text to image dreambooth training\",\n",
    "    name=\"dog-images-text-to-image\",\n",
    ")\n",
    "\n",
    "instance_data_uri_folder = workspace_ml_client.data.create_or_update(instance_data)\n",
    "\n",
    "print(instance_data_uri_folder)\n",
    "print(\"\")\n",
    "print(\"Path to folder in Blob Storage:\")\n",
    "print(instance_data_uri_folder.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Submit the fine tuning job using `diffusers_text_to_image_dreambooth_pipeline` component\n",
    " \n",
    "Create the job that uses the `diffusers_text_to_image_dreambooth_pipeline` component for `stable-diffusion-text-to-image` task. Learn more in 5.2 about all the parameters supported for fine tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Get pipeline component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINETUNE_PIPELINE_COMPONENT_NAME = \"diffusers_text_to_image_dreambooth_pipeline\"\n",
    "\n",
    "pipeline_component_transformers_func = registry_ml_client.components.get(\n",
    "    name=FINETUNE_PIPELINE_COMPONENT_NAME, label=\"latest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Create arguments to be passed to `diffusers_text_to_image_dreambooth_pipeline` component\n",
    "\n",
    "The `diffusers_text_to_image_dreambooth_pipeline` component consists of model selection and finetuning components.\n",
    "\n",
    "*Uncomment one or more parameters below to provide specific values, if you wish you override the autoselected default values. Please visit this pipeline component in Azure ML studio to know more about arguments and their allowed values.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_component_args = {\n",
    "    # # Model import args\n",
    "    \"model_family\": \"HuggingFaceImage\",\n",
    "    \"download_from_source\": False,  # True for downloading a model directly from HuggingFace\n",
    "    \"mlflow_model\": foundation_model.id,  # foundation_model.id is provided, only foundation_model gives UserErrorException: only path input is supported now but get: ...\n",
    "    # \"model_name\": huggingface_model_name, # specify the model_name instead of mlflow_model if you want to use a model from the huggingface hub\n",
    "    # # Finetune_args\n",
    "    \"task_name\": \"stable-diffusion-text-to-image\",\n",
    "    # # Instance prompt - The instance_prompt argument is a text prompt that contains a unique identifier, such as sks, and the class the image belongs to.\n",
    "    \"instance_prompt\": '\"A photo of a sks dog\"',  # Please note that we need to escape the double inverted comma.\n",
    "    \"resolution\": 512,\n",
    "    # # Prior preservation loss\n",
    "    \"with_prior_preservation\": True,\n",
    "    # Class prompt - a prompt without the unique identifier. This prompt is used for generating \"class images\" for prior preservation\n",
    "    \"class_prompt\": '\"a photo of dog\"',  # Please note that we need to escape the double inverted comma.\n",
    "    \"num_class_images\": 100,  # Number of images to generate with the class prompt for prior preservation.\n",
    "    \"class_data_dir\": None,  # Specify Datastore URI of existing uri_folder containing class images if you have, and the training job will generate any additional images so that num_class_images are present in class_data_dir during training time.\n",
    "    \"prior_generation_precision\": \"fp32\",\n",
    "    \"prior_loss_weight\": 1.0,\n",
    "    \"sample_batch_size\": 2,  # Number of samples to generate class images in each batch.\n",
    "    # # Lora parameters\n",
    "    # # LoRA reduces the number of trainable parameters by learning pairs of rank-decompostion matrices while freezing the original weights. This vastly reduces the storage requirement for large models adapted to specific tasks and enables efficient task-switching during deployment all without introducing inference latency. LoRA also outperforms several other adaptation methods including adapter, prefix-tuning, and fine-tuning.\n",
    "    \"apply_lora\": True,\n",
    "    # \"lora_alpha\": 128,\n",
    "    # \"lora_r\": 16,\n",
    "    # \"lora_dropout\": 0.0,\n",
    "    # \"tokenizer_max_length\": 77,\n",
    "    # # Text Encoder\n",
    "    \"pre_compute_text_embeddings\": True,\n",
    "    \"train_text_encoder\": False,\n",
    "    # \"text_encoder_type\": \"CLIPTextModel\",\n",
    "    # \"text_encoder_name\": \"openai/clip-vit-base-patch32\", # Huggingface id of text encoder.\n",
    "    # \"text_encoder_use_attention_mask\": False,\n",
    "    # # UNET related\n",
    "    # \"class_labels_conditioning\": \"timesteps\",\n",
    "    # # Noise Scheduler\n",
    "    \"noise_scheduler_name\": \"DDPMScheduler\",  # Optional, default is used from the base model. If following scheduler related parameters are not provided, it is taken from model's scheduler config.\n",
    "    # \"noise_scheduler_num_train_timesteps\": 1000,\n",
    "    # \"noise_scheduler_variance_type\": \"fixed_small\",\n",
    "    # \"noise_scheduler_prediction_type\": \"epsilon\",\n",
    "    # \"noise_scheduler_timestep_spacing\": \"leading\",\n",
    "    # \"extra_noise_scheduler_args\": \"clip_sample_range=1.0; clip_sample=True\" # Optional additional arguments that are supplied to noise scheduler. The arguments should be semi-colon separated key value pairs and should be enclosed in double quotes.\n",
    "    # \"offset_noise\": False\n",
    "    # # Training related\n",
    "    \"num_validation_images\": 3,  # Number of images to generate using instance_prompt. Images are stored in the output/checkpoint-* directories. Please note that this will increase the training time.\n",
    "    \"number_of_workers\": 3,\n",
    "    \"number_of_epochs\": 15,\n",
    "    \"max_steps\": -1,\n",
    "    \"training_batch_size\": 3,\n",
    "    \"auto_find_batch_size\": False,\n",
    "    \"learning_rate\": 1e-4,  # Learning rate is recommended to be set to a lower value, if not fine-tuning with Lora\n",
    "    # \"learning_rate_scheduler\": \"warmup_linear\",\n",
    "    # \"warmup_steps\": 0,\n",
    "    # \"optimizer\": \"adamw_hf\",\n",
    "    # \"weight_decay\": 0.0,\n",
    "    # \"gradient_accumulation_step\": 1,\n",
    "    # \"max_grad_norm\": 1.0,\n",
    "    \"precision\": \"32\",\n",
    "    \"random_seed\": 42,\n",
    "    \"logging_strategy\": \"epoch\",\n",
    "    # \"logging_steps\": 500,  # Number of update steps between two logs if logging_strategy='steps'.\n",
    "    \"save_total_limit\": -1,  # If you face issues related to disk space, you can limit the number of checkpoints saved.\n",
    "    \"save_as_mlflow_model\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_count_per_instance = 1  # Number of gpus to be used per node for finetuning, should be equal to number of gpu per node in the compute SKU used for finetune\n",
    "instance_count = (\n",
    "    1  # Number of nodes to be used for finetuning (used for distributed training)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that the user provides only one of mlflow_model or model_name\n",
    "if (\n",
    "    pipeline_component_args.get(\"mlflow_model\") is None\n",
    "    and pipeline_component_args.get(\"model_name\") is None\n",
    "):\n",
    "    raise ValueError(\n",
    "        \"You must specify either mlflow_model or model_name for the model to finetune\"\n",
    "    )\n",
    "if (\n",
    "    pipeline_component_args.get(\"mlflow_model\") is not None\n",
    "    and pipeline_component_args.get(\"model_name\") is not None\n",
    "):\n",
    "    raise ValueError(\n",
    "        \"You must specify ONLY one of mlflow_model and model_name for the model to finetune\"\n",
    "    )\n",
    "elif (\n",
    "    pipeline_component_args.get(\"mlflow_model\") is None\n",
    "    and pipeline_component_args.get(\"model_name\") is not None\n",
    "):\n",
    "    use_model_name = huggingface_model_name\n",
    "elif (\n",
    "    pipeline_component_args.get(\"mlflow_model\") is not None\n",
    "    and pipeline_component_args.get(\"model_name\") is None\n",
    "):\n",
    "    use_model_name = aml_registry_model_name\n",
    "print(f\"Finetuning model {use_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Utility function to create pipeline using `diffusers_text_to_image_dreambooth_pipeline` component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.dsl import pipeline\n",
    "from azure.ai.ml.entities import PipelineComponent\n",
    "from azure.ai.ml import Input\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "\n",
    "@pipeline()\n",
    "def create_pipeline_transformers():\n",
    "    \"\"\"Create pipeline.\"\"\"\n",
    "\n",
    "    diffusers_pipeline_component: PipelineComponent = (\n",
    "        pipeline_component_transformers_func(\n",
    "            compute_model_import=cluster_name,\n",
    "            compute_finetune=cluster_name,\n",
    "            instance_data_dir=Input(\n",
    "                type=AssetTypes.URI_FOLDER, path=instance_data_uri_folder.path\n",
    "            ),\n",
    "            process_count_per_instance=process_count_per_instance,\n",
    "            instance_count=instance_count,\n",
    "            **pipeline_component_args,\n",
    "        )\n",
    "    )\n",
    "    return {\n",
    "        # Map the output of the fine tuning job to the output of pipeline job so that we can easily register the fine tuned model. Registering the model is required to deploy the model to an online or batch endpoint.\n",
    "        \"trained_model\": diffusers_pipeline_component.outputs.mlflow_model_folder,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4 Run the fine tuning job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusers_pipeline_object = create_pipeline_transformers()\n",
    "\n",
    "# don't use cached results from previous jobs\n",
    "diffusers_pipeline_object.settings.force_rerun = True\n",
    "\n",
    "# set continue on step failure to False\n",
    "diffusers_pipeline_object.settings.continue_on_step_failure = False\n",
    "\n",
    "\n",
    "diffusers_pipeline_object.display_name = (\n",
    "    use_model_name + \"_diffusers_pipeline_component_run_\" + \"text2image\"\n",
    ")\n",
    "# Don't use cached results from previous jobs\n",
    "diffusers_pipeline_object.settings.force_rerun = True\n",
    "\n",
    "print(\"Submitting pipeline\")\n",
    "\n",
    "diffusers_pipeline_run = workspace_ml_client.jobs.create_or_update(\n",
    "    diffusers_pipeline_object, experiment_name=experiment_name\n",
    ")\n",
    "\n",
    "print(f\"Pipeline created. URL: {diffusers_pipeline_run.studio_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusers_pipeline_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_ml_client.jobs.stream(diffusers_pipeline_run.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Get metrics from finetune component\n",
    "\n",
    "The model training happens as part of the finetune component. Please follow below steps to extract validation metrics from the run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.1 Initialize MLFlow Client\n",
    "\n",
    "The models and artifacts that are produced by AutoML can be accessed via the MLFlow interface.\n",
    "Initialize the MLFlow client here, and set the backend as Azure ML, via. the MLFlow Client.\n",
    "\n",
    "IMPORTANT - You need to have installed the latest MLFlow packages with:\n",
    "\n",
    "    pip install azureml-mlflow\n",
    "    pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# Obtain the tracking URL from MLClient\n",
    "MLFLOW_TRACKING_URI = workspace_ml_client.workspaces.get(\n",
    "    name=workspace_ml_client.workspace_name\n",
    ").mlflow_tracking_uri\n",
    "\n",
    "print(MLFLOW_TRACKING_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the MLFLOW TRACKING URI\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "print(f\"\\nCurrent tracking uri: {mlflow.get_tracking_uri()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking.client import MlflowClient\n",
    "\n",
    "# Initialize MLFlow client\n",
    "mlflow_client = MlflowClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 Get the training run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat 'tags.mlflow.rootRunId=' and pipeline_job.name in single quotes as filter variable\n",
    "filter = \"tags.mlflow.rootRunId='\" + diffusers_pipeline_run.name + \"'\"\n",
    "runs = mlflow.search_runs(\n",
    "    experiment_names=[experiment_name], filter_string=filter, output_format=\"list\"\n",
    ")\n",
    "\n",
    "# Get the training and evaluation runs.\n",
    "# Using a hacky way till 'Bug 2320997: not able to show eval metrics in FT notebooks - mlflow client now showing display names' is fixed\n",
    "for run in runs:\n",
    "    # Check if run.data.metrics.epoch exists\n",
    "    if \"epoch\" in run.data.metrics:\n",
    "        training_run = run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3 Get training metrics\n",
    "\n",
    "Access the results (such as Models, Artifacts, Metrics) of a previously completed run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(training_run.data.metrics, index=[0]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Register the fine tuned model with the workspace\n",
    "\n",
    "We will register the model from the output of the fine tuning job. This will track lineage between the fine tuned model and the fine tuning job. The fine tuning job, further, tracks lineage to the foundation model, data and training code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Generating a unique timestamp that can be used for names and versions that need to be unique\n",
    "timestamp = str(int(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Model\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "# Check if the `trained_model` output is available\n",
    "print(\n",
    "    f\"Pipeline job outputs: {workspace_ml_client.jobs.get(diffusers_pipeline_run.name).outputs}\"\n",
    ")\n",
    "\n",
    "model_path_from_job = (\n",
    "    f\"azureml://jobs/{diffusers_pipeline_run.name}/outputs/trained_model\"\n",
    ")\n",
    "print(f\"Path to register model: {model_path_from_job}\")\n",
    "\n",
    "finetuned_model_name = f\"{use_model_name.replace('/', '-')}-dog-text-to-image\"\n",
    "finetuned_model_description = (\n",
    "    f\"{use_model_name.replace('/', '-')} fine tuned model for dog objects text to image\"\n",
    ")\n",
    "prepare_to_register_model = Model(\n",
    "    path=model_path_from_job,\n",
    "    type=AssetTypes.MLFLOW_MODEL,\n",
    "    name=finetuned_model_name,\n",
    "    version=timestamp,  # use timestamp as version to avoid version conflict\n",
    "    description=finetuned_model_description,\n",
    ")\n",
    "print(f\"Prepare to register model: \\n{prepare_to_register_model}\")\n",
    "\n",
    "# Register the model from pipeline job output\n",
    "registered_model = workspace_ml_client.models.create_or_update(\n",
    "    prepare_to_register_model\n",
    ")\n",
    "print(f\"Registered model: {registered_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Deploy the fine tuned model to an online endpoint\n",
    "Online endpoints give a durable REST API that can be used to integrate with applications that need to use the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from azure.ai.ml.entities import ManagedOnlineEndpoint, ManagedOnlineDeployment\n",
    "\n",
    "# Endpoint names need to be unique in a region, hence using timestamp to create unique endpoint name\n",
    "online_endpoint_name = \"text-to-image-dog-\" + datetime.datetime.now().strftime(\n",
    "    \"%m%d%H%M\"\n",
    ")\n",
    "online_endpoint_description = f\"Online endpoint for {registered_model.name}, finetuned for dog text to image generation task.\"\n",
    "# Create an online endpoint\n",
    "endpoint = ManagedOnlineEndpoint(\n",
    "    name=online_endpoint_name,\n",
    "    description=online_endpoint_description,\n",
    "    auth_mode=\"key\",\n",
    "    tags={\"foo\": \"bar\"},\n",
    ")\n",
    "workspace_ml_client.begin_create_or_update(endpoint).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import OnlineRequestSettings, ProbeSettings\n",
    "\n",
    "deployment_name = \"text2img-dog-mlflow-deploy\"\n",
    "\n",
    "# Create a deployment\n",
    "demo_deployment = ManagedOnlineDeployment(\n",
    "    name=deployment_name,\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    model=registered_model.id,\n",
    "    instance_type=\"Standard_NC6s_v3\",\n",
    "    instance_count=1,\n",
    "    request_settings=OnlineRequestSettings(\n",
    "        max_concurrent_requests_per_instance=1,\n",
    "        request_timeout_ms=90000,\n",
    "        max_queue_wait_ms=500,\n",
    "    ),\n",
    "    liveness_probe=ProbeSettings(\n",
    "        failure_threshold=49,\n",
    "        success_threshold=1,\n",
    "        timeout=299,\n",
    "        period=180,\n",
    "        initial_delay=180,\n",
    "    ),\n",
    "    readiness_probe=ProbeSettings(\n",
    "        failure_threshold=10,\n",
    "        success_threshold=1,\n",
    "        timeout=10,\n",
    "        period=10,\n",
    "        initial_delay=2000,\n",
    "    ),\n",
    ")\n",
    "workspace_ml_client.online_deployments.begin_create_or_update(demo_deployment).wait()\n",
    "endpoint.traffic = {deployment_name: 100}\n",
    "workspace_ml_client.begin_create_or_update(endpoint).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Test the endpoint with sample data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create request json\n",
    "import json\n",
    "\n",
    "request_json = {\n",
    "    \"input_data\": {\n",
    "        \"columns\": [\"prompt\"],\n",
    "        \"index\": [0],\n",
    "        \"data\": [\"a photo of sks dog in a bucket\"],\n",
    "    },\n",
    "    \"params\": {\n",
    "        \"height\": 512,\n",
    "        \"width\": 512,\n",
    "        \"num_inference_steps\": 50,\n",
    "        \"guidance_scale\": 7.5,\n",
    "        \"negative_prompt\": [\"blurry; three legs\"],\n",
    "        \"num_images_per_prompt\": 2,\n",
    "    },\n",
    "}\n",
    "\n",
    "request_file_name = \"sample_request_data.json\"\n",
    "with open(request_file_name, \"w\") as request_file:\n",
    "    json.dump(request_json, request_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = workspace_ml_client.online_endpoints.invoke(\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    deployment_name=deployment_name,\n",
    "    request_file=request_file_name,\n",
    ")\n",
    "responses = json.loads(responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize Generated Image(s)\n",
    "Now that we have scored a test image, we can visualize the generated images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "for response in responses:\n",
    "    base64_string = response[\"generated_image\"]\n",
    "    image_stream = BytesIO(base64.b64decode(base64_string))\n",
    "    image = Image.open(image_stream)\n",
    "    display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Clean up resources - delete the online endpoint\n",
    "Don't forget to delete the online endpoint, else you will leave the billing meter running for the compute used by the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_ml_client.online_endpoints.begin_delete(name=online_endpoint_name).wait()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama-cpp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
